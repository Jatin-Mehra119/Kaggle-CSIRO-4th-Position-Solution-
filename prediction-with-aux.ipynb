{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ffc832",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T12:08:35.283890Z",
     "iopub.status.busy": "2026-01-16T12:08:35.283630Z",
     "iopub.status.idle": "2026-01-16T12:08:35.295454Z",
     "shell.execute_reply": "2026-01-16T12:08:35.294684Z"
    },
    "papermill": {
     "duration": 0.016415,
     "end_time": "2026-01-16T12:08:35.296868",
     "exception": false,
     "start_time": "2026-01-16T12:08:35.280453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import timm\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import argparse\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "class CFG:\n",
    "    test_csv = '/kaggle/input/csiro-biomass/test.csv'\n",
    "    test_dir = '/kaggle/input/csiro-biomass/test'\n",
    "    \n",
    "    # Path to the directory containing the Aux models (v7)\n",
    "    aux_model_dir = '/kaggle/input/aux-v7/pytorch/default/1/Models_Aux_Only_v7' \n",
    "    \n",
    "    # Path to the main stage 2 models\n",
    "    main_model_dir = '/kaggle/input/vithugedinov3-with-manual-data-cleaning/pytorch/default/1'\n",
    "    \n",
    "    output_file = 'submission.csv'\n",
    "    model_name = 'vit_huge_plus_patch16_dinov3.lvd1689m'\n",
    "    img_size = 800\n",
    "    \n",
    "    # Fold weights for ensemble\n",
    "    fold_weights = {0: 0.264901, 1: 0.174089, 2: 0.157770, 3: 0.231843, 4: 0.171397}\n",
    "    \n",
    "    seeds = [42]        # Seeds for Main Model\n",
    "    aux_seeds = [44]    # Seeds for Aux Model\n",
    "    \n",
    "    batch_size = 4\n",
    "    num_workers = 2\n",
    "    targets = ['Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'Dry_Total_g']\n",
    "    \n",
    "    # TTA Toggle\n",
    "    use_tta = True\n",
    "\n",
    "# ============================================================================\n",
    "# MODELS\n",
    "# ============================================================================\n",
    "class AuxModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Architecture matches the 'BiomassModel' from the new aux training code.\n",
    "    Outputs: [NDVI, Height]\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=False, num_classes=0)\n",
    "        img_features = self.backbone.num_features\n",
    "\n",
    "        # AUXILIARY HEAD ONLY (NDVI, Height)\n",
    "        self.aux_head = nn.Sequential(\n",
    "            nn.Linear(img_features, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2) \n",
    "        )\n",
    "\n",
    "    def forward(self, image):\n",
    "        feat = self.backbone(image)\n",
    "        aux_out = self.aux_head(feat)\n",
    "        return aux_out\n",
    "\n",
    "class BiomassModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Main Stage 2 Model (unchanged, as no new training code was provided for this part).\n",
    "    Expects concatenated Image features + Encoded Tabular features.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(model_name, pretrained=False, num_classes=0)\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, CFG.img_size, CFG.img_size)\n",
    "            img_features = self.backbone(dummy_input).shape[1]\n",
    "    \n",
    "        self.tabular_encoder = nn.Sequential(\n",
    "            nn.Linear(2, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        \n",
    "        fusion_dim = img_features + 128\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(fusion_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "        \n",
    "        self.head_green = nn.Linear(256, 1)\n",
    "        self.head_dead = nn.Linear(256, 1)\n",
    "        self.head_clover = nn.Linear(256, 1)\n",
    "        self.head_gdm = nn.Linear(256, 1)\n",
    "        self.head_total = nn.Linear(256, 1)\n",
    "    \n",
    "    def forward(self, image, tabular):\n",
    "        img_features = self.backbone(image)\n",
    "        tab_features = self.tabular_encoder(tabular)\n",
    "        combined = torch.cat([img_features, tab_features], dim=1)\n",
    "        fused = self.fusion(combined)\n",
    "        \n",
    "        out_green = self.head_green(fused)\n",
    "        out_dead = self.head_dead(fused)\n",
    "        out_clover = self.head_clover(fused)\n",
    "        out_gdm = self.head_gdm(fused)\n",
    "        out_total = self.head_total(fused)\n",
    "        \n",
    "        outputs = torch.cat([out_green, out_dead, out_clover, out_gdm, out_total], dim=1)\n",
    "        return outputs\n",
    "\n",
    "# ============================================================================\n",
    "# DATA & TTA UTILS\n",
    "# ============================================================================\n",
    "class BiomassInferenceDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform, tabular_data=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.tabular_data = tabular_data\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx]['image_path'].split('/')[-1]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            image = np.zeros((CFG.img_size, CFG.img_size, 3), np.uint8)\n",
    "        else:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        image = self.transform(image=image)['image']\n",
    "        if self.tabular_data is not None:\n",
    "            return image, torch.tensor(self.tabular_data[idx], dtype=torch.float32)\n",
    "        return image\n",
    "\n",
    "def get_tta_transforms():\n",
    "    base = [A.Resize(CFG.img_size, CFG.img_size), A.Normalize(), ToTensorV2()]\n",
    "    if not CFG.use_tta:\n",
    "        return [A.Compose(base)]\n",
    "    return [\n",
    "        A.Compose(base),\n",
    "        A.Compose([A.HorizontalFlip(p=1.0)] + base),\n",
    "        A.Compose([A.VerticalFlip(p=1.0)] + base)\n",
    "    ]\n",
    "\n",
    "# ============================================================================\n",
    "# WORKER\n",
    "# ============================================================================\n",
    "def run_worker(rank, world_size):\n",
    "    device = torch.device(f'cuda:{rank}')\n",
    "    test_df = pd.read_csv(CFG.test_csv).drop_duplicates('image_path').reset_index(drop=True)\n",
    "    \n",
    "    indices = np.array_split(np.arange(len(test_df)), world_size)[rank]\n",
    "    if len(indices) == 0: return \n",
    "    my_df = test_df.iloc[indices].reset_index(drop=True)\n",
    "\n",
    "    # --- STAGE 1: AUX PREDICTIONS (FLOAT32) ---\n",
    "    aux_preds_accum = 0\n",
    "    aux_count = 0\n",
    "    \n",
    "    print(f\"[Rank {rank}] Starting Stage 1: Aux Inference...\")\n",
    "    \n",
    "    for seed in CFG.aux_seeds:\n",
    "        for fold in range(5):\n",
    "            path = os.path.join(CFG.aux_model_dir, f'best_aux_only_seed{seed}_fold{fold}.pth')\n",
    "            if not os.path.exists(path): \n",
    "                # v6 naming convention fallback\n",
    "                path_alt = os.path.join(CFG.aux_model_dir, f'best_aux_seed{seed}_fold{fold}.pth')\n",
    "                if os.path.exists(path_alt):\n",
    "                    path = path_alt\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            ckpt = torch.load(path, map_location='cpu', weights_only=False)\n",
    "            model = AuxModel(CFG.model_name).to(device)\n",
    "            model.load_state_dict(ckpt['model_state_dict'])\n",
    "            model.eval()\n",
    "            \n",
    "            loader = DataLoader(BiomassInferenceDataset(my_df, CFG.test_dir, get_tta_transforms()[0]), \n",
    "                                batch_size=CFG.batch_size, num_workers=CFG.num_workers)\n",
    "            \n",
    "            fold_aux = []\n",
    "            with torch.no_grad():\n",
    "                for img in loader:\n",
    "                    fold_aux.append(model(img.to(device)).cpu().numpy())\n",
    "            \n",
    "            if len(fold_aux) > 0:\n",
    "                res = np.vstack(fold_aux)\n",
    "                # Apply Inverse Transform (from training scaler)\n",
    "                if 'tab_scaler' in ckpt: \n",
    "                    res = ckpt['tab_scaler'].inverse_transform(res)\n",
    "                aux_preds_accum += res\n",
    "                aux_count += 1\n",
    "            del model; gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    predicted_tabular = aux_preds_accum / max(1, aux_count)\n",
    "    print(f\"[Rank {rank}] Stage 1 Complete. Models used: {aux_count}\")\n",
    "\n",
    "    # --- STAGE 2: FINAL INFERENCE (FLOAT32) ---\n",
    "    final_biomass_accum = 0\n",
    "    total_w = 0\n",
    "    tta_transforms = get_tta_transforms()\n",
    "    \n",
    "    print(f\"[Rank {rank}] Starting Stage 2: Main Inference...\")\n",
    "\n",
    "    for seed in CFG.seeds:\n",
    "        for fold, weight in CFG.fold_weights.items():\n",
    "            path = os.path.join(CFG.main_model_dir, f'best_model_seed{seed}_fold{fold}.pth')\n",
    "            if not os.path.exists(path): continue\n",
    "            \n",
    "            ckpt = torch.load(path, map_location='cpu', weights_only=False)\n",
    "            model = BiomassModel(CFG.model_name).to(device)\n",
    "            model.load_state_dict(ckpt['model_state_dict'] if 'model_state_dict' in ckpt else ckpt)\n",
    "            model.eval()\n",
    "\n",
    "            # Prepare Tabular Input (Predicted by Aux)\n",
    "            tab_input = predicted_tabular.copy()\n",
    "            if ckpt.get('tabular_scaler'): \n",
    "                tab_input = ckpt['tabular_scaler'].transform(tab_input)\n",
    "            \n",
    "            fold_tta_preds = 0\n",
    "            \n",
    "            for t_idx, transform in enumerate(tta_transforms):\n",
    "                loader = DataLoader(BiomassInferenceDataset(my_df, CFG.test_dir, transform, tabular_data=tab_input),\n",
    "                                    batch_size=CFG.batch_size, num_workers=CFG.num_workers)\n",
    "                \n",
    "                step_preds = []\n",
    "                with torch.no_grad():\n",
    "                    for img, tab in loader:\n",
    "                        step_preds.append(model(img.to(device), tab.to(device)).cpu().numpy())\n",
    "                \n",
    "                if len(step_preds) > 0:\n",
    "                    fold_tta_preds += np.vstack(step_preds)\n",
    "            \n",
    "            res = fold_tta_preds / len(tta_transforms)\n",
    "            \n",
    "            if ckpt.get('target_scaler'): \n",
    "                res = ckpt['target_scaler'].inverse_transform(res)\n",
    "            \n",
    "            final_biomass_accum += (res * weight)\n",
    "            total_w += weight\n",
    "            del model; gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    if total_w > 0:\n",
    "        final_preds = final_biomass_accum / total_w\n",
    "        img_ids = my_df['image_path'].apply(lambda x: x.split('/')[-1].replace('.jpg', '')).values\n",
    "        rows = []\n",
    "        for i, img_id in enumerate(img_ids):\n",
    "            for j, target in enumerate(CFG.targets):\n",
    "                rows.append({'sample_id': f\"{img_id}__{target}\", 'target': max(0.0, float(final_preds[i, j]))})\n",
    "        pd.DataFrame(rows).to_csv(f'temp_part_{rank}.csv', index=False)\n",
    "    else:\n",
    "        print(f\"[Rank {rank}] Warning: No Stage 2 models found!\")\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--rank', type=int, default=-1)\n",
    "    parser.add_argument('--world_size', type=int, default=2)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.rank == -1:\n",
    "        # Spawning processes for multi-GPU inference\n",
    "        processes = [subprocess.Popen([sys.executable, __file__, '--rank', str(r), '--world_size', str(args.world_size)]) for r in range(args.world_size)]\n",
    "        for p in processes: p.wait()\n",
    "        \n",
    "        dfs = []\n",
    "        for r in range(args.world_size):\n",
    "            fname = f'temp_part_{r}.csv'\n",
    "            if os.path.exists(fname):\n",
    "                dfs.append(pd.read_csv(fname))\n",
    "                os.remove(fname)\n",
    "        \n",
    "        if dfs:\n",
    "            sub = pd.concat(dfs).drop_duplicates('sample_id')\n",
    "            sub.to_csv(CFG.output_file, index=False)\n",
    "            print(f\"Submission saved to {CFG.output_file}\")\n",
    "        else:\n",
    "            print(\"Error: No predictions generated.\")\n",
    "            pd.DataFrame(columns=['sample_id', 'target']).to_csv(CFG.output_file, index=False)\n",
    "    else:\n",
    "        run_worker(args.rank, args.world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3b6498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-16T12:08:35.300253Z",
     "iopub.status.busy": "2026-01-16T12:08:35.300044Z",
     "iopub.status.idle": "2026-01-16T12:18:00.049065Z",
     "shell.execute_reply": "2026-01-16T12:18:00.048311Z"
    },
    "papermill": {
     "duration": 564.752786,
     "end_time": "2026-01-16T12:18:00.050939",
     "exception": false,
     "start_time": "2026-01-16T12:08:35.298153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\r\n",
      "  data = fetch_version_info()\r\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.12/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\r\n",
      "  data = fetch_version_info()\r\n",
      "/usr/local/lib/python3.12/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\r\n",
      "  data = fetch_version_info()\r\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\r\n",
      "  warnings.warn(\r\n",
      "[Rank 0] Starting Stage 1: Aux Inference...\r\n",
      "[Rank 0] Stage 1 Complete. Models used: 5\r\n",
      "[Rank 0] Starting Stage 2: Main Inference...\r\n",
      "Submission saved to submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "!python inference.py"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14254895,
     "isSourceIdPinned": false,
     "sourceId": 112509,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 533694,
     "modelInstanceId": 519241,
     "sourceId": 684351,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 561833,
     "modelInstanceId": 549128,
     "sourceId": 721829,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 567.834565,
   "end_time": "2026-01-16T12:18:00.370760",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-16T12:08:32.536195",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
